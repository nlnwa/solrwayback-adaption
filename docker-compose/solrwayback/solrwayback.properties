##solrwayback.properties (UTF-8)

##Url to the UWKA warc-indexer solr-server. Last part is the collectionname
solr.server=http://solr:8983/solr/solrwayback/

#Solr caching. Will be default false if not defined
solr.server.caching=true
solr.server.caching.max.entries=10000
# Age based cache invalidation is not enabled per default as index watching works better for most cases
# See the descrition of solr.server.check.interval.seconds below for more details
#solr.server.caching.age.seconds=86400

# Solr availability and index change check interval: Every x seconds a query for new documents is issued.
# If an index change is detected, caches will be cleared
#
# The check is light (cached by Solr) if the index has not changed and moderate if the index has been
# changed. If the backing index has billions of records and is continuously updated, active checking
# will strain the system. In that case it is recommended to disable active checking and use fixed time
# cache clearing with solr.server.caching.age.seconds instead.
#
# Default is 60 seconds. For a large multi sharded index, this limit should be increased to 600 seconds or higher.
# Disable by setting to -1
# If the checking is disabled, consider setting solr.server.caching.age.seconds instead
solr.server.check.interval.seconds=60

## Link to this webapp itself. BaseURL for link rewrites must be full url.
wayback.baseurl=http://localhost:8080/solrwayback/

#Disable playback if true. Will just show a simple page with error message if playback is clicked.
#Will also prevent showing full size images and download of binaries.
#Tumbnail images in search results will still be shown.
playback.disabled=false


#Set to true to prevent SolrWayback url-hacking from accessing Warc-files+offset that is not in the Solr collection.
#This can be done if location+WARC filename+offset is known for a record.
#This will have performance impact. Only set to true if there are other Warc-files mounted on the OS that must not be accessed.
warc.files.verify.collection=false

# WARC files must be resolvable for playback to work.
# Plain files as well as HTTP URLs are supported.
# For the base case when WARCS have not been moved since index time, the
# RewriteLocationResolver is used with default setup.
# If WARC files are moved to another location after index, different
# implementations of ArcFileLocationResolverInterface are available.
#
# Default resolver: Optionally rewrites the input
warc.file.resolver.class=dk.kb.netarchivesuite.solrwayback.interfaces.RewriteLocationResolver
# Default parameters for RewriteLocationResolver: Return the input path unchanged:
# warc.file.resolver.parameters.path.regexp=.*
# warc.file.resolver.parameters.path.replacement=$0
# Sample parameters for RewriteLocationResolver that handles changed root location for WARC files,
# where the subfolder structure for the WARCs is preserved:
# warc.file.resolver.parameters.path.regexp=/home/harvester/warcs/(.*)
# warc.file.resolver.parameters.path.replacement=/warcs/$1
# Sample parameters for RewriteLocationResolver that rewrites to a HTTP server where all WARCs are accessible
# directly under the "warcstore/" folder:
# warc.file.resolver.parameters.path.regexp=.*([^/]*)
# warc.file.resolver.parameters.path.replacement=http://example.com/warcstore/$1
#
# Mapping resolver: Uses a map of known WARCs
# warc.file.resolver.class=dk.kb.netarchivesuite.solrwayback.interfaces.FileMovedMappingResolver
# The FileMovedMappingResolver MUST have a file containing a list of
# full file paths for known WARCs, where a sample entry in the list could be
# /storage/warcs/col1/mywarc_123.warc.gz
# warc.file.resolver.parameters=/home/user/netarkivet.files
#
# Auto discovery: Scans folders for WARCs.
# IMPORTANT: On a networked drive with millions of WARCs, the scan might take significant time
# and IO resources. Use RewriteLocationResolver or FileMovedMappingResolver where possible.
# warc.file.resolver.class=dk.kb.netarchivesuite.solrwayback.interfaces.AutoFileResolver
# The AutoFileResolver MUST have at least one root to scan from
# warc.file.resolver.parameters.autoresolver.roots=/home/sw/warcs1,/netmounts/colfoo
# Per default, the roots are only scanned on SolrWayback start.
# Sample config for AutoFileResolver for scanning every hour:
# warc.file.resolver.parameters.autoresolver.rescan.enabled=true
# warc.file.resolver.parameters.autoresolver.rescan.seconds=3600


#Collection name. This is the name shown when exporting a page to PID-XML.
pid.collection.name=netarkivet.dk


#The possible values for url.normaliser are: normal, legacy and minimal.
# Only change the normaliser type if you know what you are doing.
# Only use minimal if the solr index was build in warc-indexer earlier that 3.0. All SolrWayback bundles have warc-indexer later than this. (Playback quality is drastically reduced)
# Use Legacy for 3.0-3.1 versions of the warc-indexer.
# Use normal for all warc-indexers version 3.2.0+
url.normaliser=normal

# Optional list of Solr-params. Format is key1=value1;key2=value2,...
#solr.search.params=f.url_norm.qf=url

#------- sharddivide export ------------------
# THIS HAS FEATURE STILL NEEDS MORE TESTING. DO NO USE IT YET. 
# Pre-SolrWayback 5.0, export always used standard Solr cursorMark for export.
# Solr cursorMark issues some redundant requests that scales with the number of shards in a Solr setup.
# sharddivide avoids redundant requests at the cost of SolrWayback memory overhead, speeding up export
# for multi-shard setups.

# Whether or not to use sharddivide. See subsequent properties when using 'auto'
# Possible values: always, never, auto (default)
solr.export.sharddivide.default=never

# When solr.export.sharddivide.default == auto, the backing Solr must have at least this number of shards
# for sharddivide to be activated.
# Default: 2
solr.export.sharddivide.autolimit.shards.default=2

# When solr.export.sharddivide.default == auto, the export query must have at least this number of hits
# for sharddivide to be activated.
# Default: 5000
solr.export.sharddivide.autolimit.hits.default=5000

# If sharddivide is used, SolrWayback will issue at most this number of concurrent requests to shards.
# Default: 20
solr.export.sharddivide.concurrent.max=20


#------- Generate preview screenshots ------------------
#Used for preview screenshots shown on the page resources overview. Is not required. 
#Chrome must be installed on the OS and headless chrome is used to generate the screenshots.
#The setup depend on the OS. 

#Linux: chrome
#Ubunutu: chrome.command=chromium-browser
#Windows: chrome.command=C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe
#MAC1: chrome.command=/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome
#MAC2: chrome.command="open -b com.google.Chrome"
#example command: chromium-browser --headless --disable-gpu --ipc-connection-timeout=3000 --screenshot=test.png --window-size=1280,1024 https://www.google.com/
chrome.command=google-chrome

# This will work on linux. Create the folder yourself  
screenshot.temp.imagedir=/tmp/solrwayback_screenshots/
#For windows (create the folder yourself)
#screenshot.temp.imagedir=C:\\solrwayback_screenshots\\

#Timeout in seconds. Optional, 20 seconds is default. 
screenshot.preview.timeout=20
#------------------------------------------------------- 